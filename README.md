irtheory

PRACTICAL – 1
Aim: Write a program to demonstrate Boolean Retrieval Model using Bitwise
operations on Term Document Incidence Matrix.
Boolean Retrieval Model:
The Boolean model of information retrieval is a classical information retrieval (IR) model
and is the first and most adopted one. It is used by virtually all commercial IR systems today.
Basic Assumption of Boolean Model
1. An index term is either present(1) or absent(0) in the document
2. All index terms provide equal evidence with respect to information needs.
3. Queries are Boolean combinations of index terms.
 X AND Y: represents doc that contains both X and Y
 X OR Y: represents doc that contains either X or Y
 NOT X: represents the doc that do not contain X
 CountVectorizer
 CountVectorizer is a great tool provided by the scikit-learn library in Python. It is 
used to transform a given text into a vector on the basis of the frequency (count) of
each word that occurs in the entire text. The value of each cell is nothing but the count
of the word in that particular text sample.
 Pandas pandas is a fast, powerful, flexible and easy to use open source data analysis
and manipulation tool, built on top of the Python programming language.

PRACTICAL-2
AIM: Implement Page Rank Algorithm.
PageRank (PR) is an algorithm used by Google Search to rank web pages in their search
engine results. It is named after both the term "web page" and co-founder Larry Page. PageRank
is a way of measuring the importance of website pages. According to Google:

PRACTICAL-3
AIM: Implement Dynamic programming algorithm for computing the edit
distance between strings s1 and s2. (Hint. Levenshtein Distance)
-->The Levenshtein distance is a string metric for measuring difference between two
sequences. Informally, the Levenshtein distance between two words is the minimum
number of single character edits (i.e., insertions, deletions or substitutions) required to
change one word into the other. It is named after Vladimir Levenshtein, who considered
this distance in 1965.
Levenshtein distance may also be referred to as edit distance

Practical-4
Aim: Write a program to Compute Similarity between two text documents.
Tokenization
A token is an instance of a sequence of characters in some particular document that
are grouped together as a useful semantic unit for processing.
Tokenization is the process of turning a meaningful piece of data, such as an account number,
into a random string of characters called a token that has no meaningful value if breached.
Tokens serve as reference to the original data, but cannot be used to guess those values.
Stop Words
 Words in a document that are frequently occuring but
meaningless in terms of Information Retrieval (IR) are
called stopwords.
In computing, stop words are words which are filtered out before or after processing of
natural language data (text). Though "stop words" usually refers to the most common words
in a language, there is no single universal list of stop words used by all-natural language
processing tools, and indeed not all tools even use such a list.
Cosine Similarity
Cosine similarity measures the similarity between two vectors by calculating the cosine of the
angle between the two vectors.

Hadoop is an Apache open source framework written in java that allows distributed
processing of large datasets across clusters of computers using simple programming
models. The Hadoop framework application works in an environment that provides
distributed storage and computation across clusters of computers.


PRACTICAL – 7
Aim: To Write a program for Pre-processing of a Text Document: stop word removal.
 Words in a document that are frequently occuring but
meaningless in terms of Information Retrieval (IR) are
called stopwords.
The list of words that are not to be added is called a stop list
Nltk
NLTK is a leading platform for building Python programs to work with human language
data
NLTK, or Natural Language Toolkit, is a Python package that you can use for NLP. A lot of
the data that you could be analyzing is unstructured data and contains human-readable text.
Punkt
This tokenizer divides a text into a list of sentences by using an unsupervised algorithm to
build a model for abbreviation words, collocations, and words that start sentences
Natural Language Toolkit (NLTK):
NLTK is an amazing library to play with natural language


Practical-9
Aim: Write a program to implement simple web crawler.
A Web crawler is a part of search engine that gathers information from the Web so that
indexer can create an index of the data. Web crawler starts the process of crawling from a
single uniform resource locator (URL) or a set of seed URL
BeautifulSoup
XML stands for extensible markup language

Information Retrieval is finding material of an unstructured nature that satisfies an
information need from within large collection.
• Information Retrieval System is mainly focus electronic searching and retrieving of documents.
















